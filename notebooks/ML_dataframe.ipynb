{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f9a5697-a50e-45e1-b047-07252557afa0",
   "metadata": {},
   "source": [
    "# Building the ML dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a207893c-6f98-4c83-b0c1-8a241b78c41d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad32155d-e98f-4351-ba14-dada857077c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set max number of columns to display; default 20\n",
    "pd.options.display.max_columns = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86d7e9b7-8a39-44bc-a77b-670c2411d40d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directory where data files will be downloaded\n",
    "cwd_path = Path.cwd()\n",
    "data_path = cwd_path.parent.joinpath('data')\n",
    "data_push_path = cwd_path.parent.joinpath('data_to_push')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594f09e2-8dfa-4537-87c8-02f59c316c2f",
   "metadata": {},
   "source": [
    "### Load in latest wind turbine data\n",
    "- Note: Only 9 turbines decommissioned before 2019!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1132,
   "id": "60756d12-c942-4221-8bfb-55539c5cb587",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30642 entries, 0 to 30641\n",
      "Data columns (total 30 columns):\n",
      " #   Column                                            Non-Null Count  Dtype              \n",
      "---  ------                                            --------------  -----              \n",
      " 0   EinheitMastrNummer                                30642 non-null  object             \n",
      " 1   DatumLetzteAktualisierung                         30642 non-null  datetime64[ns, UTC]\n",
      " 2   Bundesland                                        30642 non-null  object             \n",
      " 3   Postleitzahl                                      30642 non-null  int64              \n",
      " 4   Ort                                               30642 non-null  object             \n",
      " 5   Laengengrad                                       30642 non-null  float64            \n",
      " 6   Breitengrad                                       30642 non-null  float64            \n",
      " 7   Registrierungsdatum                               30642 non-null  datetime64[ns, UTC]\n",
      " 8   Inbetriebnahmedatum                               30642 non-null  datetime64[ns, UTC]\n",
      " 9   EinheitBetriebsstatus                             30642 non-null  object             \n",
      " 10  DatumEndgueltigeStilllegung                       1155 non-null   datetime64[ns, UTC]\n",
      " 11  DatumBeginnVoruebergehendeStilllegung             68 non-null     datetime64[ns, UTC]\n",
      " 12  DatumWiederaufnahmeBetrieb                        6 non-null      datetime64[ns, UTC]\n",
      " 13  NameStromerzeugungseinheit                        30642 non-null  object             \n",
      " 14  Nettonennleistung                                 30642 non-null  float64            \n",
      " 15  AnschlussAnHoechstOderHochSpannung                22069 non-null  float64            \n",
      " 16  Einspeisungsart                                   30204 non-null  object             \n",
      " 17  NameWindpark                                      29857 non-null  object             \n",
      " 18  Hersteller                                        30385 non-null  object             \n",
      " 19  Technologie                                       30642 non-null  object             \n",
      " 20  Typenbezeichnung                                  30380 non-null  object             \n",
      " 21  Nabenhoehe                                        30642 non-null  float64            \n",
      " 22  Rotordurchmesser                                  30642 non-null  float64            \n",
      " 23  Rotorblattenteisungssystem                        23265 non-null  float64            \n",
      " 24  area_blades                                       30642 non-null  int64              \n",
      " 25  nearest_grid_point                                30642 non-null  object             \n",
      " 26  nearest_grid_point_elevation                      30642 non-null  float64            \n",
      " 27  turbine_elevation                                 30642 non-null  float64            \n",
      " 28  nearest_grid_point_distance                       30642 non-null  float64            \n",
      " 29  turbine_elevation_relative_to_nearest_grid_point  30642 non-null  float64            \n",
      "dtypes: datetime64[ns, UTC](6), float64(11), int64(2), object(11)\n",
      "memory usage: 7.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Read in latest turbine data\n",
    "# Now only 30,642 after removing 3 turbines outside bounding box\n",
    "df_turbines = pd.read_pickle(data_push_path / 'df_turbines_knn_blades_haversine_elevation_utc.pkl')\n",
    "df_turbines.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1133,
   "id": "e8b6d791-7cdc-47cf-a229-3e7be5f1cf07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of datetime column names for convenient indexing later\n",
    "turbine_date_columns = [\n",
    "    'DatumLetzteAktualisierung',\n",
    "    'Registrierungsdatum',\n",
    "    'Inbetriebnahmedatum',\n",
    "    'DatumEndgueltigeStilllegung',\n",
    "    'DatumBeginnVoruebergehendeStilllegung',\n",
    "    'DatumWiederaufnahmeBetrieb'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "23f23d69-5644-4975-b7a8-ffa6547c372a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Cast all tz naive datetime64 columns to UTC tz aware\n",
    "# df_turbines[turbine_date_columns] = df_turbines[turbine_date_columns].apply(lambda series: series.dt.tz_localize('UTC'), axis=0)\n",
    "\n",
    "# # save to pickle\n",
    "# df_turbines.to_pickle(data_push_path / 'df_turbines_knn_blades_haversine_elevation_utc.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7afd1be-4f95-46ca-8725-c5c8fd7eb3cc",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072ead41-6439-49d1-9f7c-64802ac83833",
   "metadata": {},
   "source": [
    "# Load in all SMARD data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394288e6-6c14-4f46-a8ce-99f0ba4fc912",
   "metadata": {},
   "source": [
    "### Load in SMARD energy generated data (actual measured generation)\n",
    "- My response variable `y` (aka target/label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1134,
   "id": "da86b8a3-c807-4621-8fe2-76067cc762e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get all SMARD CSV files, load into dataframes, and concat them\n",
    "\n",
    "def load_SMARD_generated_data():\n",
    "    \"\"\"\n",
    "    Look for CSV files in the SMARD directory\n",
    "    \"\"\"\n",
    "    list_of_dataframes = []\n",
    "    for filepath in data_path.joinpath('SMARD').iterdir():\n",
    "        if filepath.name.startswith('Realisierte_Erzeugung'):\n",
    "            list_of_dataframes.append(pd.read_csv(filepath, sep=';'))\n",
    "            \n",
    "    # Check that num of rows is what I expect after concatenating dfs\n",
    "    num_of_rows = 0\n",
    "    for df in list_of_dataframes:\n",
    "        num_of_rows += len(df)\n",
    "    \n",
    "    # concat dataframes\n",
    "    df = pd.concat(list_of_dataframes)\n",
    "    print(f'Number of rows match up: {num_of_rows == len(df)}')\n",
    "    \n",
    "    # Select columns to keep\n",
    "    # Note: I'm using the interval start time to create the timestamps\n",
    "    # ERA5 surface parameters are instantaneous so can't perfectly align anyway\n",
    "    df = df[[\n",
    "        'Datum',\n",
    "        'Anfang',\n",
    "        # 'Ende',\n",
    "        'Wind Onshore [MWh] Berechnete Auflösungen'\n",
    "    ]]\n",
    "    \n",
    "    # rename columns\n",
    "    df.rename(columns={\n",
    "        'Datum': 'date',\n",
    "        'Anfang': 'interval_start_time', \n",
    "        # 'Ende': 'interval_end_time',\n",
    "        'Wind Onshore [MWh] Berechnete Auflösungen': 'actual_generated_smard_mwh'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Handle dates and times to create unified datetime64 timestamps\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%d.%m.%Y')\n",
    "    df['start_time_delta'] = pd.to_timedelta(df['interval_start_time'] + ':00')\n",
    "    df['datetime_cet'] = df['date'] + df['start_time_delta']\n",
    "    # Add CET timezone info and infer change from CET->CEST->CET, etc\n",
    "    df['datetime_cet'] = df['datetime_cet'].dt.tz_localize(tz='CET', ambiguous='infer')\n",
    "    \n",
    "    # Drop un-needed columns\n",
    "    df = df.drop(columns=['date', 'start_time_delta', 'interval_start_time'])\n",
    "    # Re-arrange columns\n",
    "    df = df[['datetime_cet', 'actual_generated_smard_mwh']]\n",
    "    \n",
    "    # Convert European thousands and decimal seperators in values to (US/UK) decimal full stop format\n",
    "    translation_table = str.maketrans({'.': None, ',': '.'})\n",
    "    df['actual_generated_smard_mwh'] = df['actual_generated_smard_mwh'].str.translate(translation_table).astype(float)\n",
    "    \n",
    "    # Sort rows by datetime_cet\n",
    "    df.sort_values('datetime_cet', inplace=True)\n",
    "    # Reset index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1135,
   "id": "24e68d75-5a7f-470d-957e-2323ecb3b23a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows match up: True\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49655 entries, 0 to 49654\n",
      "Data columns (total 2 columns):\n",
      " #   Column                      Non-Null Count  Dtype              \n",
      "---  ------                      --------------  -----              \n",
      " 0   datetime_cet                49655 non-null  datetime64[ns, CET]\n",
      " 1   actual_generated_smard_mwh  49655 non-null  float64            \n",
      "dtypes: datetime64[ns, CET](1), float64(1)\n",
      "memory usage: 776.0 KB\n"
     ]
    }
   ],
   "source": [
    "# Load SMARD data\n",
    "df_smard_generated = load_SMARD_generated_data()\n",
    "df_smard_generated.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "id": "b5c04cd6-c69b-4f24-ae2f-a97192f1add6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime_cet                  0\n",
       "actual_generated_smard_mwh    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_smard_generated.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03ae16e-a4b7-4174-9e46-8e48fc6310a9",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee3ed30-dd65-4a6d-8526-b4f97478de70",
   "metadata": {},
   "source": [
    "### Load in SMARD day-ahead prices\n",
    "- Wholesale prices: https://www.smard.de/page/en/wiki-article/5884/5976\n",
    "- This is the day-ahead price!\n",
    "    - \"Weighted wholesale electricity price (day-ahead price on the exchange) for each hour [€/MWh] determined on the day-ahead auction that took place ones on the previous day - data is delivered no later than 2 hours after trading closes. Source: ENTSO-E\"\n",
    "- Data only goes back to 2018-10-01 (October 1, 2018)\n",
    "- This is for the bidding area Germany/Luxembourg (not just Germany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "id": "58b57c79-8906-45b3-88b1-80be43113775",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get all SMARD CSV files, load into dataframes, and concat them\n",
    "\n",
    "def load_SMARD_market_price_data():\n",
    "    \"\"\"\n",
    "    Look for CSV files in the SMARD directory\n",
    "    \"\"\"\n",
    "    list_of_dataframes = []\n",
    "    for filepath in data_path.joinpath('SMARD').iterdir():\n",
    "        if filepath.name.startswith('Gro_handelspreise'):\n",
    "            list_of_dataframes.append(pd.read_csv(filepath, sep=';', na_values='-'))\n",
    "            \n",
    "    # Check that num of rows is what I expect after concatenating dfs\n",
    "    num_of_rows = 0\n",
    "    for df in list_of_dataframes:\n",
    "        num_of_rows += len(df)\n",
    "    \n",
    "    # concat dataframes\n",
    "    df = pd.concat(list_of_dataframes)\n",
    "    print(f'Number of rows match up: {num_of_rows == len(df)}')\n",
    "    \n",
    "    # Select columns to keep\n",
    "    # Note: I'm using the interval start time to create the timestamps\n",
    "    # ERA5 surface parameters are instantaneous so can't perfectly align anyway\n",
    "    df = df[[\n",
    "        'Datum',\n",
    "        'Anfang',\n",
    "        # 'Ende',\n",
    "        'Deutschland/Luxemburg [€/MWh] Originalauflösungen'\n",
    "    ]]\n",
    "    \n",
    "    # rename columns\n",
    "    df.rename(columns={\n",
    "        'Datum': 'date',\n",
    "        'Anfang': 'interval_start_time', \n",
    "        # 'Ende': 'interval_end_time',\n",
    "        'Deutschland/Luxemburg [€/MWh] Originalauflösungen': 'day_ahead_price_eur_mwh'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Handle dates and times to create unified datetime64 timestamps\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%d.%m.%Y')\n",
    "    df['start_time_delta'] = pd.to_timedelta(df['interval_start_time'] + ':00')\n",
    "    df['datetime_cet'] = df['date'] + df['start_time_delta']\n",
    "    # Add CET timezone info and infer change from CET->CEST->CET, etc\n",
    "    df['datetime_cet'] = df['datetime_cet'].dt.tz_localize(tz='CET', ambiguous='infer')\n",
    "    \n",
    "    # Drop un-needed columns\n",
    "    df = df.drop(columns=['date', 'start_time_delta', 'interval_start_time'])\n",
    "    # Re-arrange columns\n",
    "    df = df[['datetime_cet', 'day_ahead_price_eur_mwh']]\n",
    "    \n",
    "    # Convert European thousands and decimal seperators in values to (US/UK) decimal full stop format\n",
    "    translation_table = str.maketrans({'.': None, ',': '.'})\n",
    "    df['day_ahead_price_eur_mwh'] = df['day_ahead_price_eur_mwh'].str.translate(translation_table).astype(float)\n",
    "    \n",
    "    # Drop the numerous (700+) duplicate rows\n",
    "    df.drop_duplicates(subset='datetime_cet', inplace=True)\n",
    "    # Sort rows by datetime_cet\n",
    "    df.sort_values('datetime_cet', inplace=True)\n",
    "    # Reset index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "id": "0ba10680-0ec5-4008-8b61-efc90d159c21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows match up: True\n"
     ]
    }
   ],
   "source": [
    "df_smard_market_price = load_SMARD_market_price_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "id": "711e5f87-95df-4c49-af34-5790dab56acf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime_cet                  0\n",
       "day_ahead_price_eur_mwh    6551\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_smard_market_price.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "id": "07a8495e-e2c7-44a3-acb2-8b744038b2a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    43104.000000\n",
       "mean        97.537291\n",
       "std        106.238714\n",
       "min       -500.000000\n",
       "25%         35.260000\n",
       "50%         55.155000\n",
       "75%        118.750000\n",
       "max        871.000000\n",
       "Name: day_ahead_price_eur_mwh, dtype: float64"
      ]
     },
     "execution_count": 1140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_smard_market_price['day_ahead_price_eur_mwh'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1390efc-5355-4ea2-a6a0-347edb76b444",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e0627e-fdce-497a-80b6-33bec255295e",
   "metadata": {},
   "source": [
    "### Load in SMARD installed capacity data\n",
    "- Note: CSV reader infers decimal comma (European) format 54.499 as decimal point 54.499 even though it's 54,499.00!\n",
    "    - Specify dtype of column in the read_csv method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "id": "f361fedf-2472-4048-8039-67f9230d05e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_SMARD_installed_capacity_data():\n",
    "    \"\"\"\n",
    "    Look for CSV files in the SMARD directory\n",
    "    \"\"\"\n",
    "    list_of_dataframes = []\n",
    "    for filepath in data_path.joinpath('SMARD').iterdir():\n",
    "        if filepath.name.startswith('Installierte_Erzeugungsleistung'):\n",
    "            list_of_dataframes.append(\n",
    "                pd.read_csv(filepath, sep=';', dtype={'Wind Onshore [MW] Berechnete Auflösungen': str})\n",
    "            )\n",
    "            \n",
    "    # Check that num of rows is what I expect after concatenating dfs\n",
    "    num_of_rows = 0\n",
    "    for df in list_of_dataframes:\n",
    "        num_of_rows += len(df)\n",
    "    \n",
    "    # concat dataframes\n",
    "    df = pd.concat(list_of_dataframes)\n",
    "    print(f'Number of rows match up: {num_of_rows == len(df)}')\n",
    "    \n",
    "    # Select columns to keep\n",
    "    # Note: I'm using the interval start time to create the timestamps\n",
    "    # ERA5 surface parameters are instantaneous so can't perfectly align anyway\n",
    "    df = df[[\n",
    "        'Datum',\n",
    "        'Anfang',\n",
    "        # 'Ende',\n",
    "        'Wind Onshore [MW] Berechnete Auflösungen'\n",
    "    ]]\n",
    "    \n",
    "    # rename columns\n",
    "    df.rename(columns={\n",
    "        'Datum': 'date',\n",
    "        'Anfang': 'interval_start_time', \n",
    "        # 'Ende': 'interval_end_time',\n",
    "        'Wind Onshore [MW] Berechnete Auflösungen': 'total_nominal_capacity_smard_mw'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Handle dates and times to create unified datetime64 timestamps\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%d.%m.%Y')\n",
    "    df['start_time_delta'] = pd.to_timedelta(df['interval_start_time'] + ':00')\n",
    "    df['datetime_cet'] = df['date'] + df['start_time_delta']\n",
    "    # Add CET timezone info and infer change from CET->CEST->CET, etc\n",
    "    df['datetime_cet'] = df['datetime_cet'].dt.tz_localize(tz='CET', ambiguous='infer')\n",
    "    \n",
    "    # Drop un-needed columns\n",
    "    df = df.drop(columns=['date', 'start_time_delta', 'interval_start_time'])\n",
    "    # Re-arrange columns\n",
    "    df = df[['datetime_cet', 'total_nominal_capacity_smard_mw']]\n",
    "    \n",
    "    # Convert European thousands and decimal seperators in values to (US/UK) decimal full stop format\n",
    "    translation_table = str.maketrans({'.': None, ',': '.'})\n",
    "    df['total_nominal_capacity_smard_mw'] = df['total_nominal_capacity_smard_mw'].str.translate(translation_table).astype(float)\n",
    "    \n",
    "    # Sort rows by datetime_cet\n",
    "    df.sort_values('datetime_cet', inplace=True)\n",
    "    # Reset index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "id": "888a84e1-95e8-4921-a7d4-df7db6a234af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows match up: True\n"
     ]
    }
   ],
   "source": [
    "df_smard_installed_capacity = load_SMARD_installed_capacity_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "id": "94ed203e-734c-460f-a350-6ca262ba7be6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49655 entries, 0 to 49654\n",
      "Data columns (total 2 columns):\n",
      " #   Column                           Non-Null Count  Dtype              \n",
      "---  ------                           --------------  -----              \n",
      " 0   datetime_cet                     49655 non-null  datetime64[ns, CET]\n",
      " 1   total_nominal_capacity_smard_mw  49655 non-null  float64            \n",
      "dtypes: datetime64[ns, CET](1), float64(1)\n",
      "memory usage: 776.0 KB\n"
     ]
    }
   ],
   "source": [
    "df_smard_installed_capacity.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1144,
   "id": "6fd4bfd2-ec57-40b3-88f8-1511ff39073d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime_cet                       0\n",
       "total_nominal_capacity_smard_mw    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_smard_installed_capacity.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4831fa1f-bb2a-4b9f-ae27-2f9cdaeb8a00",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ddb688-d9f2-40b5-839f-82073d53ba6a",
   "metadata": {},
   "source": [
    "### Load in SMARD day-ahead generation forecast\n",
    "- Wind Onshore [MWh] Berechnete Auflösungen for Germany\n",
    "- Only has 24 missing values for the day of 2022-12-21 (verified on SMARD data visuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "id": "a33ca2cf-0d43-4582-9ff2-dc710d7906a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_SMARD_forecasted_generation_data():\n",
    "    \"\"\"\n",
    "    Look for CSV files in the SMARD directory\n",
    "    \"\"\"\n",
    "    list_of_dataframes = []\n",
    "    for filepath in data_path.joinpath('SMARD').iterdir():\n",
    "        if filepath.name.startswith('Prognostizierte_Erzeugung_Day-Ahead'):\n",
    "            list_of_dataframes.append(pd.read_csv(filepath, sep=';', na_values='-'))\n",
    "            \n",
    "    # Check that num of rows is what I expect after concatenating dfs\n",
    "    num_of_rows = 0\n",
    "    for df in list_of_dataframes:\n",
    "        num_of_rows += len(df)\n",
    "    \n",
    "    # concat dataframes\n",
    "    df = pd.concat(list_of_dataframes)\n",
    "    print(f'Number of rows match up: {num_of_rows == len(df)}')\n",
    "    \n",
    "    # Select columns to keep\n",
    "    # Note: I'm using the interval start time to create the timestamps\n",
    "    # ERA5 surface parameters are instantaneous so can't perfectly align anyway\n",
    "    df = df[[\n",
    "        'Datum',\n",
    "        'Anfang',\n",
    "        # 'Ende',\n",
    "        'Wind Onshore [MWh] Berechnete Auflösungen'\n",
    "    ]]\n",
    "    \n",
    "    # rename columns\n",
    "    df.rename(columns={\n",
    "        'Datum': 'date',\n",
    "        'Anfang': 'interval_start_time', \n",
    "        # 'Ende': 'interval_end_time',\n",
    "        'Wind Onshore [MWh] Berechnete Auflösungen': 'forecasted_generation_smard_mwh'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Handle dates and times to create unified datetime64 timestamps\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%d.%m.%Y')\n",
    "    df['start_time_delta'] = pd.to_timedelta(df['interval_start_time'] + ':00')\n",
    "    df['datetime_cet'] = df['date'] + df['start_time_delta']\n",
    "    # Add CET timezone info and infer change from CET->CEST->CET, etc\n",
    "    df['datetime_cet'] = df['datetime_cet'].dt.tz_localize(tz='CET', ambiguous='infer')\n",
    "    \n",
    "    # Drop un-needed columns\n",
    "    df = df.drop(columns=['date', 'start_time_delta', 'interval_start_time'])\n",
    "    # Re-arrange columns\n",
    "    df = df[['datetime_cet', 'forecasted_generation_smard_mwh']]\n",
    "    \n",
    "    # Convert European thousands and decimal seperators in values to (US/UK) decimal full stop format\n",
    "    translation_table = str.maketrans({'.': None, ',': '.'})\n",
    "    # df['forecasted_generation_smard_mwh'] = df['forecasted_generation_smard_mwh'].str.translate(translation_table).astype(float)\n",
    "        \n",
    "    # Sort rows by datetime_cet\n",
    "    df.sort_values('datetime_cet', inplace=True)\n",
    "    # Reset index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "id": "3b1658ac-b2a4-47f3-9b4a-7bf9df8e9ebc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows match up: True\n"
     ]
    }
   ],
   "source": [
    "df_smard_forecasted_generation = load_SMARD_forecasted_generation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "id": "e35dc963-ee2a-4cd6-9633-6f3eebec9dfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49655 entries, 0 to 49654\n",
      "Data columns (total 2 columns):\n",
      " #   Column                           Non-Null Count  Dtype              \n",
      "---  ------                           --------------  -----              \n",
      " 0   datetime_cet                     49655 non-null  datetime64[ns, CET]\n",
      " 1   forecasted_generation_smard_mwh  49631 non-null  object             \n",
      "dtypes: datetime64[ns, CET](1), object(1)\n",
      "memory usage: 776.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_smard_forecasted_generation.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1148,
   "id": "ea0d11dd-8560-42c0-a903-82c777eb78f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime_cet                        0\n",
       "forecasted_generation_smard_mwh    24\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_smard_forecasted_generation.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38422baf-a79f-49b9-835d-d4b5d1cf61c7",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba2c31b-6791-481a-b358-f087fa3420c7",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de974db7-3217-4bdf-a4c1-aa2eba699b22",
   "metadata": {},
   "source": [
    "# Begin building ML dataframe `df_main`\n",
    "- Start with one full year: 2022\n",
    "    - Then bring in another year like 2021 and run through the same transformations and then concat along datetimeindex?\n",
    "- Good resource on time-related feature engineering: https://scikit-learn.org/stable/auto_examples/applications/plot_cyclical_feature_engineering.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "id": "6fbe7769-32ac-446d-a262-f11297b79026",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_utc</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>month_number</th>\n",
       "      <th>year</th>\n",
       "      <th>meteorological_season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 01:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 02:00:00+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 03:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 04:00:00+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49651</th>\n",
       "      <td>2023-08-31 19:00:00+00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49652</th>\n",
       "      <td>2023-08-31 20:00:00+00:00</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49653</th>\n",
       "      <td>2023-08-31 21:00:00+00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49654</th>\n",
       "      <td>2023-08-31 22:00:00+00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49655</th>\n",
       "      <td>2023-08-31 23:00:00+00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>summer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49656 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datetime_utc  hour  day_of_week  day_of_month  \\\n",
       "0     2018-01-01 00:00:00+00:00     0            0             1   \n",
       "1     2018-01-01 01:00:00+00:00     1            0             1   \n",
       "2     2018-01-01 02:00:00+00:00     2            0             1   \n",
       "3     2018-01-01 03:00:00+00:00     3            0             1   \n",
       "4     2018-01-01 04:00:00+00:00     4            0             1   \n",
       "...                         ...   ...          ...           ...   \n",
       "49651 2023-08-31 19:00:00+00:00    19            3            31   \n",
       "49652 2023-08-31 20:00:00+00:00    20            3            31   \n",
       "49653 2023-08-31 21:00:00+00:00    21            3            31   \n",
       "49654 2023-08-31 22:00:00+00:00    22            3            31   \n",
       "49655 2023-08-31 23:00:00+00:00    23            3            31   \n",
       "\n",
       "       month_number  year meteorological_season  \n",
       "0                 1  2018                winter  \n",
       "1                 1  2018                winter  \n",
       "2                 1  2018                winter  \n",
       "3                 1  2018                winter  \n",
       "4                 1  2018                winter  \n",
       "...             ...   ...                   ...  \n",
       "49651             8  2023                summer  \n",
       "49652             8  2023                summer  \n",
       "49653             8  2023                summer  \n",
       "49654             8  2023                summer  \n",
       "49655             8  2023                summer  \n",
       "\n",
       "[49656 rows x 7 columns]"
      ]
     },
     "execution_count": 1149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make time zone aware UTC?\n",
    "datetime_index_utc = pd.date_range(start='2018-01-01', end='2023-08-31 23:59:59', freq='H', name='datetime_utc', tz='UTC')\n",
    "\n",
    "# Make index to dataframe and reset\n",
    "df_main = datetime_index_utc.to_frame().reset_index(drop=True)\n",
    "\n",
    "# Extract properties and derive new columns\n",
    "df_main['hour'] = df_main['datetime_utc'].dt.hour\n",
    "# 0-6 (Monday-Sunday)\n",
    "df_main['day_of_week'] = df_main['datetime_utc'].dt.dayofweek\n",
    "df_main['day_of_month'] = df_main['datetime_utc'].dt.day\n",
    "df_main['month_number'] = df_main['datetime_utc'].dt.month\n",
    "df_main['year'] = df_main['datetime_utc'].dt.year\n",
    "\n",
    "# Function to get meteorological season based on month number (1-12)\n",
    "# Should I just go ahead and encode the discrete numerical value?\n",
    "def get_meteorological_season(month):\n",
    "    if 3 <= month <= 5:\n",
    "        return 'spring'\n",
    "    elif 6 <= month <= 8:\n",
    "        return 'summer'\n",
    "    elif 9 <= month <= 11:\n",
    "        return 'autumn'\n",
    "    else:\n",
    "        return 'winter'\n",
    "    \n",
    "df_main['meteorological_season'] = df_main['month_number'].apply(get_meteorological_season)\n",
    "\n",
    "df_main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dcf113-d403-4117-89d2-bece362f52cc",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4958a86a-adc1-4399-bbf1-4d0f4ad1a26e",
   "metadata": {},
   "source": [
    "## Derive new columns `turbines_in_operation` and `total_nominal_capacity_operational_turbines_mw`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ba8c6d-52fb-479e-9fd0-8a9a0d6702ee",
   "metadata": {},
   "source": [
    "#### Function to check if turbine operational at a given UTC hour timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "id": "67ca575e-6270-484d-9ae1-1515ade674ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_operational(timestamp_utc, df_turbines):\n",
    "    \"\"\"\n",
    "    Inputs: hourly tz aware utc timestamps, turbine dataframe\n",
    "    Get a bool series of turbines that are operational at the time of the [hourly] timestamp\n",
    "    \"\"\"\n",
    "    # Turbines that went into operation before the timestamp; returns bool series for bool indexing\n",
    "    started_operations = df_turbines['Inbetriebnahmedatum'] <= timestamp_utc\n",
    "\n",
    "    # Turbines already decommissioned before the timestamp; returns bool series for bool indexing\n",
    "    already_decommissioned = df_turbines['DatumEndgueltigeStilllegung'] <= timestamp_utc\n",
    "\n",
    "    # Turbines that went into maintenance before timestamp and haven't come back into operation before the timestamp\n",
    "    # Note: Some turbines go straight from temporary maintenance to decommissioned without ever going back into operation\n",
    "    still_in_maintenance_or_decommissioned = (df_turbines['DatumBeginnVoruebergehendeStilllegung'] <= timestamp_utc) & \\\n",
    "    ((df_turbines['DatumWiederaufnahmeBetrieb'] > timestamp_utc) | df_turbines['DatumWiederaufnahmeBetrieb'].isna())\n",
    "\n",
    "    # Number of turbines operational at the timestamp\n",
    "    # Note the tildas to inverse these bool series\n",
    "    # This is a bool series with df_turbines index\n",
    "    turbines_in_operation_bool_series = (started_operations & ~already_decommissioned & ~still_in_maintenance_or_decommissioned)\n",
    "\n",
    "    return turbines_in_operation_bool_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd13a8b-8e19-4d98-a673-11b469fc868b",
   "metadata": {},
   "source": [
    "##### Derive column for total turbines in operation for every hourly timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "id": "5cd5411d-7359-452f-b6de-7ab18e1d2d11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1min 7s to run for 2018-23\n",
    "df_main['turbines_in_operation'] = df_main['datetime_utc'].apply(lambda timestamp: is_operational(timestamp, df_turbines).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16931cec-e622-40ba-9c0c-87ec1719debd",
   "metadata": {},
   "source": [
    "##### Derive column for total nominal capacity for every hourly timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "id": "ea22436c-4276-43a7-b002-b23c07a97a66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nettonennleistung is in kW; I divide by 1_000 to convert kilo-watts (kW) to mega-watts (MW)\n",
    "# 1min 30s to run for 2018-23\n",
    "df_main['total_nominal_capacity_operational_turbines_mw'] = df_main['datetime_utc'].apply(\n",
    "    lambda timestamp: df_turbines.loc[:, 'Nettonennleistung'].loc[is_operational(timestamp, df_turbines)].sum() / 1_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c47e39f-135c-4110-917a-d1f9c29ebda6",
   "metadata": {},
   "source": [
    "#### Save progress to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "id": "6ae08b6e-b45b-4038-a0f5-e7acef9bdfca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_main.to_pickle(data_push_path / 'df_main.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "id": "10150896-efe0-496d-a60c-1ae77165da5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_main['turbines_in_operation'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "id": "27ca57a6-aff7-4627-ba3d-52c42d828fa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_main['total_nominal_capacity_operational_turbines_mw'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "id": "874c4dca-addc-4089-ae3a-726eafa79e0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49656 entries, 0 to 49655\n",
      "Data columns (total 9 columns):\n",
      " #   Column                                          Non-Null Count  Dtype              \n",
      "---  ------                                          --------------  -----              \n",
      " 0   datetime_utc                                    49656 non-null  datetime64[ns, UTC]\n",
      " 1   hour                                            49656 non-null  int32              \n",
      " 2   day_of_week                                     49656 non-null  int32              \n",
      " 3   day_of_month                                    49656 non-null  int32              \n",
      " 4   month_number                                    49656 non-null  int32              \n",
      " 5   year                                            49656 non-null  int32              \n",
      " 6   meteorological_season                           49656 non-null  object             \n",
      " 7   turbines_in_operation                           49656 non-null  int64              \n",
      " 8   total_nominal_capacity_operational_turbines_mw  49656 non-null  float64            \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), int32(5), int64(1), object(1)\n",
      "memory usage: 5.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_main.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0486df29-ed07-4d11-ae78-4163d385c03a",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d489ca-6e9c-48b8-b18d-0db331af9f0f",
   "metadata": {},
   "source": [
    "## Merge SMARD data onto `df_main` on key datetime\n",
    "- Dataframes to merge with `df_main`:\n",
    "    - `df_smard_generated`\n",
    "    - `df_smard_market_price`\n",
    "    - `df_smard_installed_capacity`\n",
    "    - `df_smard_forecasted_generation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdcf8a4-c57f-42d1-908f-b9a5e2d48da7",
   "metadata": {},
   "source": [
    "##### Load in latest `df_main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "id": "1eb7f5ec-2e30-4a9a-8ff0-28bf9b72cfa3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49656 entries, 0 to 49655\n",
      "Data columns (total 9 columns):\n",
      " #   Column                                          Non-Null Count  Dtype              \n",
      "---  ------                                          --------------  -----              \n",
      " 0   datetime_utc                                    49656 non-null  datetime64[ns, UTC]\n",
      " 1   hour                                            49656 non-null  int32              \n",
      " 2   day_of_week                                     49656 non-null  int32              \n",
      " 3   day_of_month                                    49656 non-null  int32              \n",
      " 4   month_number                                    49656 non-null  int32              \n",
      " 5   year                                            49656 non-null  int32              \n",
      " 6   meteorological_season                           49656 non-null  object             \n",
      " 7   turbines_in_operation                           49656 non-null  int64              \n",
      " 8   total_nominal_capacity_operational_turbines_mw  49656 non-null  float64            \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), int32(5), int64(1), object(1)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_main = pd.read_pickle(data_push_path / 'df_main.pkl')\n",
    "df_main.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c31e8a-2660-4491-a68c-7224b22bfd88",
   "metadata": {},
   "source": [
    "##### Merge operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "id": "697d6021-be1c-4874-8266-8508ff0e707e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generated data; the response variable `y`\n",
    "# keep the datetime_cet column for reference\n",
    "df_main = df_main.merge(df_smard_generated, left_on='datetime_utc', right_on='datetime_cet', how='left')\n",
    "\n",
    "# The day-ahead price data\n",
    "# -> only add suffix to overlapping columns in right df being merged\n",
    "df_main = df_main.merge(df_smard_market_price, left_on='datetime_utc', right_on='datetime_cet', how='left', suffixes=(None, '_remove'))\n",
    "\n",
    "# Installed capacity\n",
    "df_main = df_main.merge(df_smard_installed_capacity, left_on='datetime_utc', right_on='datetime_cet', how='left', suffixes=(None, '_remove'))\n",
    "\n",
    "# The day-ahead forecasted generation\n",
    "df_main = df_main.merge(df_smard_forecasted_generation, left_on='datetime_utc', right_on='datetime_cet', how='left', suffixes=(None, '_remove'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b738de-ee0b-450a-ad4e-01e3318235da",
   "metadata": {},
   "source": [
    "##### Remove all the duplicate `datetime_cet` columns with suffix `_remove`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "id": "5655764f-e82b-4a63-a11e-7256cc6cf730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filter using regex; $ binds the expression to end of a string\n",
    "df_main.drop(df_main.filter(regex='_remove$').columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4e597b-c5d9-4f21-a0e4-959b23fe9e2e",
   "metadata": {},
   "source": [
    "#### Save progress to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "id": "2d05a351-b65b-407e-8fd1-16f5a88466ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_main.to_pickle(data_push_path / 'df_main_smard.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc861e1-e05e-49f5-825b-104aebf38b64",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbbe83f-7094-4ea0-a603-ac7009bb54a6",
   "metadata": {},
   "source": [
    "## Next step here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb39edde-4525-483d-a75b-812abdb53aed",
   "metadata": {},
   "source": [
    "##### Load in latest `df_main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "id": "98ccf7a8-8827-48f2-a7ae-bf4521ddf910",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49656 entries, 0 to 49655\n",
      "Data columns (total 14 columns):\n",
      " #   Column                                          Non-Null Count  Dtype              \n",
      "---  ------                                          --------------  -----              \n",
      " 0   datetime_utc                                    49656 non-null  datetime64[ns, UTC]\n",
      " 1   hour                                            49656 non-null  int32              \n",
      " 2   day_of_week                                     49656 non-null  int32              \n",
      " 3   day_of_month                                    49656 non-null  int32              \n",
      " 4   month_number                                    49656 non-null  int32              \n",
      " 5   year                                            49656 non-null  int32              \n",
      " 6   meteorological_season                           49656 non-null  object             \n",
      " 7   turbines_in_operation                           49656 non-null  int64              \n",
      " 8   total_nominal_capacity_operational_turbines_mw  49656 non-null  float64            \n",
      " 9   datetime_cet                                    49654 non-null  datetime64[ns, CET]\n",
      " 10  actual_generated_smard_mwh                      49654 non-null  float64            \n",
      " 11  day_ahead_price_eur_mwh                         43104 non-null  float64            \n",
      " 12  total_nominal_capacity_smard_mw                 49654 non-null  float64            \n",
      " 13  forecasted_generation_smard_mwh                 49630 non-null  object             \n",
      "dtypes: datetime64[ns, CET](1), datetime64[ns, UTC](1), float64(4), int32(5), int64(1), object(2)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_main = pd.read_pickle(data_push_path / 'df_main_smard.pkl')\n",
    "df_main.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "id": "f0d1a827-0bcc-425e-813d-794bfa56b46b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime_utc                                         0\n",
       "hour                                                 0\n",
       "day_of_week                                          0\n",
       "day_of_month                                         0\n",
       "month_number                                         0\n",
       "year                                                 0\n",
       "meteorological_season                                0\n",
       "turbines_in_operation                                0\n",
       "total_nominal_capacity_operational_turbines_mw       0\n",
       "datetime_cet                                         2\n",
       "actual_generated_smard_mwh                           2\n",
       "day_ahead_price_eur_mwh                           6552\n",
       "total_nominal_capacity_smard_mw                      2\n",
       "forecasted_generation_smard_mwh                     26\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "id": "ae0688b8-4904-4528-87ce-e16c3f3121b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_utc</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>month_number</th>\n",
       "      <th>year</th>\n",
       "      <th>meteorological_season</th>\n",
       "      <th>turbines_in_operation</th>\n",
       "      <th>total_nominal_capacity_operational_turbines_mw</th>\n",
       "      <th>datetime_cet</th>\n",
       "      <th>actual_generated_smard_mwh</th>\n",
       "      <th>day_ahead_price_eur_mwh</th>\n",
       "      <th>total_nominal_capacity_smard_mw</th>\n",
       "      <th>forecasted_generation_smard_mwh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>winter</td>\n",
       "      <td>27468</td>\n",
       "      <td>49734.697897</td>\n",
       "      <td>2018-01-01 01:00:00+01:00</td>\n",
       "      <td>29638.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51633.0</td>\n",
       "      <td>29.632,75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 01:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>winter</td>\n",
       "      <td>27468</td>\n",
       "      <td>49734.697897</td>\n",
       "      <td>2018-01-01 02:00:00+01:00</td>\n",
       "      <td>30173.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51633.0</td>\n",
       "      <td>30.978,75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 02:00:00+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>winter</td>\n",
       "      <td>27468</td>\n",
       "      <td>49734.697897</td>\n",
       "      <td>2018-01-01 03:00:00+01:00</td>\n",
       "      <td>31021.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51633.0</td>\n",
       "      <td>32.154,25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 03:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>winter</td>\n",
       "      <td>27468</td>\n",
       "      <td>49734.697897</td>\n",
       "      <td>2018-01-01 04:00:00+01:00</td>\n",
       "      <td>31015.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51633.0</td>\n",
       "      <td>33.045,5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 04:00:00+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>winter</td>\n",
       "      <td>27468</td>\n",
       "      <td>49734.697897</td>\n",
       "      <td>2018-01-01 05:00:00+01:00</td>\n",
       "      <td>31534.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51633.0</td>\n",
       "      <td>33.644,5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49651</th>\n",
       "      <td>2023-08-31 19:00:00+00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>summer</td>\n",
       "      <td>29445</td>\n",
       "      <td>59571.404737</td>\n",
       "      <td>2023-08-31 21:00:00+02:00</td>\n",
       "      <td>11080.75</td>\n",
       "      <td>125.50</td>\n",
       "      <td>57590.0</td>\n",
       "      <td>9.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49652</th>\n",
       "      <td>2023-08-31 20:00:00+00:00</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>summer</td>\n",
       "      <td>29445</td>\n",
       "      <td>59571.404737</td>\n",
       "      <td>2023-08-31 22:00:00+02:00</td>\n",
       "      <td>11553.25</td>\n",
       "      <td>106.03</td>\n",
       "      <td>57590.0</td>\n",
       "      <td>9.885,75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49653</th>\n",
       "      <td>2023-08-31 21:00:00+00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>summer</td>\n",
       "      <td>29445</td>\n",
       "      <td>59571.404737</td>\n",
       "      <td>2023-08-31 23:00:00+02:00</td>\n",
       "      <td>11290.00</td>\n",
       "      <td>96.89</td>\n",
       "      <td>57590.0</td>\n",
       "      <td>10.282,5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49654</th>\n",
       "      <td>2023-08-31 22:00:00+00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>summer</td>\n",
       "      <td>29445</td>\n",
       "      <td>59571.404737</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49655</th>\n",
       "      <td>2023-08-31 23:00:00+00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>summer</td>\n",
       "      <td>29445</td>\n",
       "      <td>59571.404737</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49656 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datetime_utc  hour  day_of_week  day_of_month  \\\n",
       "0     2018-01-01 00:00:00+00:00     0            0             1   \n",
       "1     2018-01-01 01:00:00+00:00     1            0             1   \n",
       "2     2018-01-01 02:00:00+00:00     2            0             1   \n",
       "3     2018-01-01 03:00:00+00:00     3            0             1   \n",
       "4     2018-01-01 04:00:00+00:00     4            0             1   \n",
       "...                         ...   ...          ...           ...   \n",
       "49651 2023-08-31 19:00:00+00:00    19            3            31   \n",
       "49652 2023-08-31 20:00:00+00:00    20            3            31   \n",
       "49653 2023-08-31 21:00:00+00:00    21            3            31   \n",
       "49654 2023-08-31 22:00:00+00:00    22            3            31   \n",
       "49655 2023-08-31 23:00:00+00:00    23            3            31   \n",
       "\n",
       "       month_number  year meteorological_season  turbines_in_operation  \\\n",
       "0                 1  2018                winter                  27468   \n",
       "1                 1  2018                winter                  27468   \n",
       "2                 1  2018                winter                  27468   \n",
       "3                 1  2018                winter                  27468   \n",
       "4                 1  2018                winter                  27468   \n",
       "...             ...   ...                   ...                    ...   \n",
       "49651             8  2023                summer                  29445   \n",
       "49652             8  2023                summer                  29445   \n",
       "49653             8  2023                summer                  29445   \n",
       "49654             8  2023                summer                  29445   \n",
       "49655             8  2023                summer                  29445   \n",
       "\n",
       "       total_nominal_capacity_operational_turbines_mw  \\\n",
       "0                                        49734.697897   \n",
       "1                                        49734.697897   \n",
       "2                                        49734.697897   \n",
       "3                                        49734.697897   \n",
       "4                                        49734.697897   \n",
       "...                                               ...   \n",
       "49651                                    59571.404737   \n",
       "49652                                    59571.404737   \n",
       "49653                                    59571.404737   \n",
       "49654                                    59571.404737   \n",
       "49655                                    59571.404737   \n",
       "\n",
       "                   datetime_cet  actual_generated_smard_mwh  \\\n",
       "0     2018-01-01 01:00:00+01:00                    29638.00   \n",
       "1     2018-01-01 02:00:00+01:00                    30173.75   \n",
       "2     2018-01-01 03:00:00+01:00                    31021.50   \n",
       "3     2018-01-01 04:00:00+01:00                    31015.00   \n",
       "4     2018-01-01 05:00:00+01:00                    31534.00   \n",
       "...                         ...                         ...   \n",
       "49651 2023-08-31 21:00:00+02:00                    11080.75   \n",
       "49652 2023-08-31 22:00:00+02:00                    11553.25   \n",
       "49653 2023-08-31 23:00:00+02:00                    11290.00   \n",
       "49654                       NaT                         NaN   \n",
       "49655                       NaT                         NaN   \n",
       "\n",
       "       day_ahead_price_eur_mwh  total_nominal_capacity_smard_mw  \\\n",
       "0                          NaN                          51633.0   \n",
       "1                          NaN                          51633.0   \n",
       "2                          NaN                          51633.0   \n",
       "3                          NaN                          51633.0   \n",
       "4                          NaN                          51633.0   \n",
       "...                        ...                              ...   \n",
       "49651                   125.50                          57590.0   \n",
       "49652                   106.03                          57590.0   \n",
       "49653                    96.89                          57590.0   \n",
       "49654                      NaN                              NaN   \n",
       "49655                      NaN                              NaN   \n",
       "\n",
       "      forecasted_generation_smard_mwh  \n",
       "0                           29.632,75  \n",
       "1                           30.978,75  \n",
       "2                           32.154,25  \n",
       "3                            33.045,5  \n",
       "4                            33.644,5  \n",
       "...                               ...  \n",
       "49651                           9.225  \n",
       "49652                        9.885,75  \n",
       "49653                        10.282,5  \n",
       "49654                             NaN  \n",
       "49655                             NaN  \n",
       "\n",
       "[49656 rows x 14 columns]"
      ]
     },
     "execution_count": 1164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ea98d1-284c-4a5c-a711-8a62305a47f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course_project",
   "language": "python",
   "name": "course_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
